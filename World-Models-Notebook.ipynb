{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# World Models\n",
    "\n",
    "### 1. V-Model\n",
    "\n",
    "### 2. M-Model\n",
    "\n",
    "### 3. C-Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym.spaces import Box\n",
    "import numpy as np\n",
    "\n",
    "try:\n",
    "    import cv2\n",
    "except ImportError:\n",
    "    cv2 = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sebastian/anaconda3/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"CarRacing-v0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1175..1473 -> 298-tiles track\n"
     ]
    }
   ],
   "source": [
    "state = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(state)\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96, 96, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bring observation in desired shape and scale observation between 0 and 1\n",
    "class ObservationWrapper(gym.Wrapper):\n",
    "    def __init__(self, env, image_size=(64,64,3), scale_obs=True):\n",
    "        super().__init__(env)\n",
    "        self.shape = image_size\n",
    "        self.screen_size = image_size[0]\n",
    "        self.scale_obs = scale_obs\n",
    "        _low, _high, _obs_dtype = (0, 255, np.uint8) if not scale_obs else (0, 1, np.float32)\n",
    "        self.observation_space = Box(low=_low, high=_high, shape=image_size, dtype=_obs_dtype)\n",
    "        \n",
    "    def step(self, action):\n",
    "        obs, reward, done, info = self.env.step(action)\n",
    "        return self._get_obs(state), reward, done, info\n",
    "    \n",
    "    def reset(self):\n",
    "        obs = self.env.reset()\n",
    "        return self._get_obs(obs)\n",
    "        \n",
    "    \n",
    "    def _get_obs(self, obs):\n",
    "        obs = cv2.resize(obs, (self.screen_size, self.screen_size), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "        if self.scale_obs:\n",
    "            obs = np.asarray(obs, dtype=np.float32) / 255.0\n",
    "        return obs\n",
    "    \n",
    "class PytorchWrapper(gym.Wrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "        \n",
    "    def step(self, action):\n",
    "        obs, reward, done, info = self.env.step(action)\n",
    "        obs = torch.from_numpy(obs).reshape((3,64,64))\n",
    "        return obs, reward, done, info\n",
    "    \n",
    "    def reset(self):\n",
    "        obs = self.env.reset()\n",
    "        obs = torch.from_numpy(obs).reshape((3,64,64))\n",
    "        return obs\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = ObservationWrapper(env, image_size=(64,64,3), scale_obs=True)\n",
    "env = PytorchWrapper(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1148..1439 -> 291-tiles track\n"
     ]
    }
   ],
   "source": [
    "state = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        ...,\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ]],\n",
       "\n",
       "       [[0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        ...,\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ]],\n",
       "\n",
       "       [[0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        ...,\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.        , 0.        , 0.        ],\n",
       "        [0.22352941, 0.22352941, 0.22352941],\n",
       "        [0.2784314 , 0.2784314 , 0.2784314 ],\n",
       "        ...,\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ]],\n",
       "\n",
       "       [[0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        ...,\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ]],\n",
       "\n",
       "       [[0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        ...,\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ]]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Normal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V-Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE():\n",
    "    def __init__(self, state_size, latent_size_N=32):\n",
    "              \n",
    "        self.encoder = Encoder(state_size, latent_size_N)\n",
    "        self.decoder = Decoder(state_size, latent_size_N)\n",
    "        \n",
    "        \n",
    "    def forward(self, image: torch.Tensor)-> torch.Tensor:\n",
    "        \n",
    "        assert image.shape == (3, 64, 64), \"Input Image as wrong shape!\"\n",
    "        encoded = self.encoder(image)\n",
    "        \n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "    \n",
    "    def encode_state(self, image: torch.Tensor)-> torch.Tensor:\n",
    "        assert image.shape == (3, 64, 64), \"Input Image as wrong shape!\"\n",
    "        encoded = self.encoder(image)\n",
    "        return encoded\n",
    "        \n",
    "        \n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, state_size, latent_size_N=32):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=4, stride=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=4, stride=2)\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=4, stride=2)\n",
    "        self.conv4 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=4, stride=2)\n",
    "        self.output_mu = nn.Linear(1024, latent_size_N)\n",
    "        self.output_sig = nn.Linear(1024, latent_size_N)\n",
    "        self.softplus = nn.Softplus() #use different activation?\n",
    "        \n",
    "    \n",
    "    def forward(self, img):\n",
    "        \n",
    "        x = torch.relu(self.conv1(img))\n",
    "        print(x.shape)\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        print(x.shape)\n",
    "        x = torch.relu(self.conv3(x))\n",
    "        print(x.shape)\n",
    "        x = torch.relu(self.conv4(x))\n",
    "        print(x.shape)\n",
    "        \n",
    "        mu = torch.tanh(self.output_mu(x.flatten(1)))\n",
    "        sig = self.softplus(self.output_sig(x.flatten(1)))\n",
    "        \n",
    "        dist = Normal(mu, sig) # in the paper they had different sample methods this one and mu + sig *N(0,1)\n",
    "        \n",
    "        latent_vector_z = dist.sample()\n",
    "            \n",
    "        return latent_vector_z\n",
    "\n",
    "        \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, state_size, latent_size_N=32):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.in_linear = nn.Linear(32, 1024)\n",
    "        self.deconv1 = nn.ConvTranspose2d(in_channels=1024, out_channels=128, kernel_size=5)\n",
    "        self.deconv2 = nn.ConvTranspose2d(in_channels=128, out_channels=64, kernel_size=5, stride=2)\n",
    "        self.deconv3 = nn.ConvTranspose2d(in_channels=64, out_channels=32, kernel_size=6, stride=2)\n",
    "        self.deconv4 = nn.ConvTranspose2d(in_channels=32, out_channels=3, kernel_size=6, stride=2)\n",
    "        \n",
    "    def forward(self, latent_vector):\n",
    "        \n",
    "        x = torch.relu(self.in_linear(latent_vector)).unsqueeze(-1).unsqueeze(-1)\n",
    "        x = torch.relu(self.deconv1(x))\n",
    "        print(x.shape)\n",
    "        x = torch.relu(self.deconv2(x))\n",
    "        print(x.shape)\n",
    "        x = torch.relu(self.deconv3(x))\n",
    "        print(x.shape)\n",
    "        x = torch.sigmoid(self.deconv4(x))\n",
    "        print(x.shape)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder((64,64,3))\n",
    "decoder = Decoder((64,64,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 32, 31, 31])\n",
      "torch.Size([1, 64, 14, 14])\n",
      "torch.Size([1, 128, 6, 6])\n",
      "torch.Size([1, 256, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "out = encoder(state.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 128, 5, 5])\n",
      "torch.Size([1, 64, 13, 13])\n",
      "torch.Size([1, 32, 30, 30])\n",
      "torch.Size([1, 3, 64, 64])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.4784, 0.4792, 0.4793,  ..., 0.4775, 0.4792, 0.4780],\n",
       "          [0.4820, 0.4798, 0.4816,  ..., 0.4803, 0.4785, 0.4802],\n",
       "          [0.4793, 0.4821, 0.4785,  ..., 0.4766, 0.4776, 0.4779],\n",
       "          ...,\n",
       "          [0.4793, 0.4816, 0.4796,  ..., 0.4800, 0.4800, 0.4799],\n",
       "          [0.4791, 0.4783, 0.4776,  ..., 0.4781, 0.4798, 0.4792],\n",
       "          [0.4792, 0.4814, 0.4798,  ..., 0.4797, 0.4796, 0.4791]],\n",
       "\n",
       "         [[0.4911, 0.4923, 0.4918,  ..., 0.4901, 0.4912, 0.4905],\n",
       "          [0.4930, 0.4914, 0.4923,  ..., 0.4928, 0.4923, 0.4932],\n",
       "          [0.4897, 0.4924, 0.4915,  ..., 0.4905, 0.4914, 0.4907],\n",
       "          ...,\n",
       "          [0.4895, 0.4913, 0.4885,  ..., 0.4916, 0.4912, 0.4900],\n",
       "          [0.4927, 0.4920, 0.4932,  ..., 0.4935, 0.4914, 0.4925],\n",
       "          [0.4916, 0.4919, 0.4906,  ..., 0.4929, 0.4925, 0.4914]],\n",
       "\n",
       "         [[0.5172, 0.5177, 0.5187,  ..., 0.5194, 0.5182, 0.5189],\n",
       "          [0.5191, 0.5208, 0.5204,  ..., 0.5191, 0.5186, 0.5198],\n",
       "          [0.5167, 0.5149, 0.5169,  ..., 0.5165, 0.5187, 0.5168],\n",
       "          ...,\n",
       "          [0.5207, 0.5195, 0.5203,  ..., 0.5187, 0.5176, 0.5189],\n",
       "          [0.5183, 0.5201, 0.5178,  ..., 0.5169, 0.5178, 0.5169],\n",
       "          [0.5192, 0.5184, 0.5179,  ..., 0.5178, 0.5182, 0.5182]]]],\n",
       "       grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# M-Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MModel(nn.Module):\n",
    "    def __init__(self, action_size, latent_size=32, hidden_size=256, batch_size=64, n_gaussians=5, rnn_type=\"LSTM\"):\n",
    "        super(MModel, self).__init__()\n",
    "        \n",
    "        self.input_shape = action_size+latent_size\n",
    "        self.action_size = action_size\n",
    "        self.latent_size = latent_size\n",
    "        self.n_gaussians = n_gaussians\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        if rnn_type == \"LSTM\":\n",
    "            self.rnn_layer = nn.LSTM(self.input_shape, hidden_size, batch_first=True)\n",
    "        elif rnn_type == \"GRU\":\n",
    "            self.rnn_layer = nn.GRU(self.input_shape, hidden_size, batch_first=True)\n",
    "            \n",
    "        self.pi_layer = nn.Linear(hidden_size, n_gaussians*latent_size)\n",
    "        self.mu_layer = nn.Linear(hidden_size, n_gaussians*latent_size)\n",
    "        self.sig_layer = nn.Linear(hidden_size, n_gaussians*latent_size)\n",
    "        \n",
    "        \n",
    "    def forward(self, latent_vector: torch.Tensor, action:torch.Tensor, hidden_state=None)-> torch.Tensor:\n",
    "        \"\"\" Simple forward pass with the RNN \"\"\"\n",
    "        \n",
    "        assert latent_vector.shape == (latent_vector.shape[0], self.latent_size), \"Latent vector has the wrong shape!\"\n",
    "        assert action.shape == (action.shape[0], self.action_size), \"Action batch has the wrong shape!\"\n",
    "        \n",
    "        input_tensor = torch.cat((latent_vector, action),dim=1).unsqueeze(1)\n",
    "        assert input_tensor.shape == (action.shape[0], 1, self.input_shape), \"input_tensor has wrong shape!\"\n",
    "        \n",
    "        output, hidden_state = self.rnn_layer(input_tensor, hidden_state)\n",
    "        \n",
    "        (pi, mu, sigma) = self.get_gauss_coeffs(output)\n",
    "        return (pi, mu, sigma), hidden_state\n",
    "    \n",
    "    \n",
    "    def get_gauss_coeffs(self, y:torch.Tensor):\n",
    "        \n",
    "        rollout_length = y.size(1)\n",
    "        \n",
    "        pi = self.pi_layer(y)\n",
    "        mu = self.mu_layer(y)\n",
    "        sigma = self.sig_layer(y)\n",
    "        \n",
    "        pi = pi.view(-1, rollout_length, self.n_gaussians, self.latent_size)\n",
    "        mu = mu.view(-1, rollout_length, self.n_gaussians, self.latent_size)\n",
    "        sigma = sigma.view(-1, rollout_length, self.n_gaussians, self.latent_size)\n",
    "        \n",
    "        pi = F.softmax(pi, 2)\n",
    "        sigma = torch.exp(sigma)\n",
    "        return pi, mu, sigma\n",
    "    \n",
    "    def predict_next_z(self,latent_vector: torch.Tensor, action:torch.Tensor, tau: float, hidden_state=None)-> torch.Tensor:\n",
    "        \"\"\" Predicts the next Latent Vector Z \"\"\"\n",
    "        values, hidden_state = self.forward(latent_vector, action, hidden_state)\n",
    "        mu, sigma = values[1], values[2]\n",
    "        \n",
    "        dist = Normal(mu, sigma*tau)\n",
    "        z_ = dist.sample().mean(2)\n",
    "        print(z_.shape)\n",
    "        \n",
    "        prediction = [torch.normal(mu, sigma)[:, :, i, :] for i in range(self.n_gaussians)]\n",
    "        return prediction, hidden_state\n",
    "        \n",
    "# M-Model loss calculation\n",
    "def mdn_loss_fn(y, pi, mu, sigma):\n",
    "    m = Normal(loc=mu, scale=sigma)\n",
    "    loss = torch.exp(m.log_prob(y))\n",
    "    loss = torch.sum(loss * pi, dim=2)\n",
    "    loss = -torch.log(loss)\n",
    "    return loss.mean()\n",
    "\n",
    "\n",
    "def criterion(y, pi, mu, sigma):\n",
    "    y = y.unsqueeze(2)\n",
    "    return mdn_loss_fn(y, pi, mu, sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_model = MModel(action_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "action = torch.ones((1,4))\n",
    "z, hidden = m_model(out, action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 32])\n"
     ]
    }
   ],
   "source": [
    "z_, h = m_model.predict_next_z(out, action, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 32])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_[4].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
